import pandas as pd
import numpy as np
import re
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨ï¼šå¤„ç†è¡¨å¤´æ ‡å‡†åŒ–å’Œæ•°æ®ç±»å‹è½¬æ¢"""
    
    def __init__(self):
        # è¡¨å¤´æ ‡å‡†åŒ–æ˜ å°„
        self.header_mapping = {
            # å­¦æ ¡ç›¸å…³
            'å­¦æ ¡   ä»£ç ': 'å­¦æ ¡ä»£ç ',
            'å­¦æ ¡ä»£ç ': 'å­¦æ ¡ä»£ç ',
            'å­¦æ ¡  ä»£ç ': 'å­¦æ ¡ä»£ç ',
            'å­¦æ ¡åç§°': 'å­¦æ ¡åç§°',
            'å­¦æ ¡  åç§°': 'å­¦æ ¡åç§°',
            
            # ç­çº§ç›¸å…³
            'ç­   åˆ«': 'ç­åˆ«',
            'ç­åˆ«': 'ç­åˆ«',
            'ç­çº§': 'ç­åˆ«',
            'ç­  åˆ«': 'ç­åˆ«',
            
            # ç§‘ä»»æ•™å¸ˆç›¸å…³
            'è¯­æ–‡ç§‘ä»»': 'è¯­æ–‡ç§‘ä»»',
            'æ•°å­¦ç§‘ä»»': 'æ•°å­¦ç§‘ä»»',
            'è‹±è¯­ç§‘ä»»': 'è‹±è¯­ç§‘ä»»',
            'ç‰©ç†ç§‘ä»»': 'ç‰©ç†ç§‘ä»»',
            'åŒ–å­¦ç§‘ä»»': 'åŒ–å­¦ç§‘ä»»',
            'é“æ³•ç§‘ä»»': 'é“æ³•ç§‘ä»»',
            'å†å²ç§‘ä»»': 'å†å²ç§‘ä»»',
            'åœ°ç†ç§‘ä»»': 'åœ°ç†ç§‘ä»»',
            'ç”Ÿç‰©ç§‘ä»»': 'ç”Ÿç‰©ç§‘ä»»',
            'ç§‘å­¦ç§‘ä»»': 'ç§‘å­¦ç§‘ä»»',
        }
        
        # è€ƒè¯•åˆ—åæ ‡å‡†åŒ–è§„åˆ™
        self.exam_column_patterns = {
            # è€ƒè¯•åç§°æ ‡å‡†åŒ–
            'exam_names': ['ä¸­è€ƒ', 'äºŒæ¨¡', 'ä¹å¹´ä¸Š', 'å…«å¹´ä¸‹', 'å…«å¹´ä¸Š', 'ä¸ƒå¹´ä¸‹', 'ä¸ƒå¹´ä¸Š', 
                          'å…­å¹´ä¸‹', 'å…­å¹´ä¸Š', 'äº”å¹´ä¸‹', 'äº”å¹´ä¸Š', 'å››å¹´ä¸‹', 'å››å¹´ä¸Š', 
                          'ä¸‰å¹´ä¸‹', 'ä¸‰å¹´ä¸Š', 'ä¸ƒå¹´å…¥'],
            
            # ç§‘ç›®åç§°æ ‡å‡†åŒ–
            'subjects': ['è¯­æ–‡', 'æ•°å­¦', 'è‹±è¯­', 'ç‰©ç†', 'åŒ–å­¦', 'é“æ³•', 'å†å²', 'åœ°ç†', 'ç”Ÿç‰©', 'ç§‘å­¦'],
            
            # æŒ‡æ ‡åç§°æ ‡å‡†åŒ–
            'metrics': ['å¹³å‡åˆ†', 'ä¼˜ç§€ç‡', 'ä¼˜è‰¯ç‡', 'åˆæ ¼ç‡', 'ä½åˆ†ç‡'],
            
            # åç¼€æ ‡å‡†åŒ–
            'suffixes': ['p1', 'p2', 'p3', 'p4', 'y1', 'y2', 'y3', 'y4', 
                        'l1', 'l2', 'l3', 'l4', 'h1', 'h2', 'h3', 'h4', 
                        'd1', 'd2', 'd3', 'd4']
        }
        
        # åˆ—ååˆ†éš”ç¬¦é…ç½®
        self.separator = '_'  # ä½¿ç”¨ä¸‹åˆ’çº¿ä½œä¸ºåˆ†éš”ç¬¦
        
        # æ•°å€¼åˆ—æ¨¡å¼ï¼ˆç”¨äºè¯†åˆ«éœ€è¦è½¬æ¢çš„åˆ—ï¼‰
        self.numeric_patterns = [
            r'.*å¹³å‡åˆ†.*',
            r'.*ä¼˜ç§€ç‡.*',
            r'.*ä¼˜è‰¯ç‡.*',
            r'.*åˆæ ¼ç‡.*',
            r'.*ä½åˆ†ç‡.*',
            r'.*æ€»åˆ†.*',
            r'.*å¾—åˆ†.*',
            r'.*æ’å.*',
            r'.*å·®å€¼.*'
        ]
        
        # éœ€è¦è½¬æ¢ä¸ºæ•°å€¼çš„åˆ—åç¼€
        self.numeric_suffixes = ['p1', 'p2', 'p3', 'p4', 'y1', 'y2', 'y3', 'y4', 
                               'l1', 'l2', 'l3', 'l4', 'h1', 'h2', 'h3', 'h4', 
                               'd1', 'd2', 'd3', 'd4']
    
    def clean_headers(self, df):
        """æ¸…æ´—å’Œæ ‡å‡†åŒ–è¡¨å¤´"""
        logger.info("å¼€å§‹æ¸…æ´—è¡¨å¤´...")
        
        # åˆ›å»ºæ–°çš„åˆ—ååˆ—è¡¨
        new_columns = []
        cleaned_mapping = {}
        
        for col in df.columns:
            original_col = col
            cleaned_col = col
            
            # 1. å»é™¤é¦–å°¾ç©ºæ ¼
            if isinstance(col, str):
                cleaned_col = col.strip()
            
            # 2. å…ˆåº”ç”¨æ ‡å‡†åŒ–æ˜ å°„ï¼ˆåœ¨ç©ºæ ¼å¤„ç†ä¹‹å‰ï¼‰
            if cleaned_col in self.header_mapping:
                cleaned_col = self.header_mapping[cleaned_col]
                logger.info(f"åº”ç”¨åˆ—åæ˜ å°„: '{original_col}' -> '{cleaned_col}'")
            else:
                # 3. å¯¹äºéå…³é”®åˆ—åï¼Œå¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
                if isinstance(col, str):
                    # å»é™¤å¤šä½™ç©ºæ ¼ï¼ˆå°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼‰
                    cleaned_col = re.sub(r'\s+', '_', cleaned_col)
                    
                    # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ï¼‰
                    cleaned_col = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\-_]', '', cleaned_col)
                    
                    # æ ‡å‡†åŒ–ä¸‹åˆ’çº¿ï¼ˆç¡®ä¿å•ä¸ªä¸‹åˆ’çº¿åˆ†éš”ï¼Œå»é™¤å¤šä½™ä¸‹åˆ’çº¿ï¼‰
                    cleaned_col = re.sub(r'_+', '_', cleaned_col)
            
            # 4. æ ‡å‡†åŒ–è€ƒè¯•åˆ—å
            cleaned_col = self._standardize_exam_column_name(cleaned_col)
            
            # 4. è®°å½•æ¸…æ´—æ˜ å°„å…³ç³»
            if original_col != cleaned_col:
                cleaned_mapping[original_col] = cleaned_col
                logger.info(f"è¡¨å¤´æ¸…æ´—: '{original_col}' -> '{cleaned_col}'")
            
            new_columns.append(cleaned_col)
        
        # æ›´æ–°DataFrameçš„åˆ—å
        df.columns = new_columns
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åˆ—å
        duplicate_cols = df.columns[df.columns.duplicated()].tolist()
        if duplicate_cols:
            logger.warning(f"å‘ç°é‡å¤åˆ—å: {duplicate_cols}")
            # ä¸ºé‡å¤åˆ—åæ·»åŠ åç¼€ï¼ˆç®€å•æ–¹æ³•ï¼‰
            new_columns = []
            seen_columns = {}
            
            for col in df.columns:
                if col in seen_columns:
                    seen_columns[col] += 1
                    new_col = f"{col}_{seen_columns[col]}"
                    new_columns.append(new_col)
                    logger.info(f"é‡å‘½åé‡å¤åˆ—: '{col}' -> '{new_col}'")
                else:
                    seen_columns[col] = 0
                    new_columns.append(col)
            
            df.columns = new_columns
            logger.info("å·²è‡ªåŠ¨å¤„ç†é‡å¤åˆ—å")
        
        logger.info(f"è¡¨å¤´æ¸…æ´—å®Œæˆï¼Œå…±å¤„ç† {len(cleaned_mapping)} ä¸ªåˆ—å")
        return df, cleaned_mapping
    
    def convert_data_types(self, df):
        """è½¬æ¢æ•°æ®ç±»å‹å’ŒéªŒè¯æ•°æ®"""
        logger.info("å¼€å§‹æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯...")
        
        conversion_stats = {
            'numeric_converted': 0,
            'null_values_filled': 0,
            'invalid_values_fixed': 0
        }
        
        for col in df.columns:
            if not isinstance(col, str):
                continue
                
            # 1. è¯†åˆ«æ•°å€¼åˆ—
            is_numeric_col = False
            for pattern in self.numeric_patterns:
                if re.match(pattern, col):
                    is_numeric_col = True
                    break
            
            # æ£€æŸ¥åˆ—åç¼€
            if not is_numeric_col:
                for suffix in self.numeric_suffixes:
                    if col.endswith(suffix) or f'   {suffix}' in col:
                        is_numeric_col = True
                        break
            
            if is_numeric_col:
                logger.info(f"å¤„ç†æ•°å€¼åˆ—: {col}")
                
                # 2. æ•°æ®ç±»å‹è½¬æ¢
                original_dtype = df[col].dtype
                
                # å¤„ç†ç©ºå€¼å’Œå¼‚å¸¸å€¼
                df[col] = self._clean_numeric_column(df[col])
                
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                try:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    conversion_stats['numeric_converted'] += 1
                    
                    # æ£€æŸ¥è½¬æ¢åçš„æ•°æ®ç±»å‹
                    new_dtype = df[col].dtype
                    if original_dtype != new_dtype:
                        logger.info(f"  ç±»å‹è½¬æ¢: {original_dtype} -> {new_dtype}")
                    
                    # 3. æ•°å€¼èŒƒå›´éªŒè¯
                    self._validate_numeric_range(df[col], col)
                    
                except Exception as e:
                    logger.error(f"  åˆ— {col} æ•°å€¼è½¬æ¢å¤±è´¥: {e}")
        
        # 4. å¤„ç†ç©ºå€¼
        null_counts = df.isnull().sum()
        total_null = null_counts.sum()
        if total_null > 0:
            logger.info(f"å‘ç° {total_null} ä¸ªç©ºå€¼")
            conversion_stats['null_values_filled'] = total_null
        
        logger.info(f"æ•°æ®ç±»å‹è½¬æ¢å®Œæˆ:")
        logger.info(f"  æ•°å€¼åˆ—è½¬æ¢: {conversion_stats['numeric_converted']}")
        logger.info(f"  ç©ºå€¼å¤„ç†: {conversion_stats['null_values_filled']}")
        
        return df, conversion_stats
    
    def _standardize_exam_column_name(self, column_name):
        """æ ‡å‡†åŒ–è€ƒè¯•åˆ—åï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´"""
        if not isinstance(column_name, str):
            return column_name
        
        # æ ‡å‡†åŒ–ä¸‹åˆ’çº¿ï¼ˆç¡®ä¿å•ä¸ªä¸‹åˆ’çº¿åˆ†éš”ï¼‰
        standardized_col = re.sub(r'_+', '_', column_name.strip())
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è€ƒè¯•åˆ—å
        is_exam_column = False
        for exam_name in self.exam_column_patterns['exam_names']:
            if exam_name in standardized_col:
                is_exam_column = True
                break
        
        if not is_exam_column:
            return standardized_col
        
        # æ ‡å‡†åŒ–è€ƒè¯•åˆ—åæ ¼å¼
        # ç›®æ ‡æ ¼å¼: "è€ƒè¯•å_ç§‘ç›®_æŒ‡æ ‡_åç¼€"
        
        # 1. è¯†åˆ«è€ƒè¯•åç§°
        exam_name = None
        for exam in self.exam_column_patterns['exam_names']:
            if exam in standardized_col:
                exam_name = exam
                break
        
        # 2. è¯†åˆ«ç§‘ç›®åç§°
        subject_name = None
        for subject in self.exam_column_patterns['subjects']:
            if subject in standardized_col:
                subject_name = subject
                break
        
        # 3. è¯†åˆ«æŒ‡æ ‡åç§°
        metric_name = None
        for metric in self.exam_column_patterns['metrics']:
            if metric in standardized_col:
                metric_name = metric
                break
        
        # 4. è¯†åˆ«åç¼€
        suffix = None
        for suffix_pattern in self.exam_column_patterns['suffixes']:
            if suffix_pattern in standardized_col:
                suffix = suffix_pattern
                break
        
        # 5. é‡æ–°ç»„è£…æ ‡å‡†æ ¼å¼
        if exam_name and subject_name and metric_name:
            if suffix:
                standardized_col = f"{exam_name}_{subject_name}_{metric_name}_{suffix}"
            else:
                standardized_col = f"{exam_name}_{subject_name}_{metric_name}"
            
            logger.debug(f"è€ƒè¯•åˆ—åæ ‡å‡†åŒ–: '{column_name}' -> '{standardized_col}'")
        
        return standardized_col
    
    def _clean_numeric_column(self, series):
        """æ¸…ç†æ•°å€¼åˆ—çš„æ•°æ®"""
        if series.dtype in ['int64', 'float64']:
            return series
        
        # å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„æ•°å€¼
        if series.dtype == 'object':
            # å»é™¤ç™¾åˆ†å·
            series = series.astype(str).str.replace('%', '')
            
            # å»é™¤ç©ºæ ¼
            series = series.str.strip()
            
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦
            series = series.str.replace('ï¼Œ', '.')  # ä¸­æ–‡é€—å·è½¬è‹±æ–‡ç‚¹
            series = series.str.replace(',', '.')  # è‹±æ–‡é€—å·è½¬è‹±æ–‡ç‚¹
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            series = series.replace(['', 'nan', 'None', 'NULL'], np.nan)
            
            # å¤„ç†å¼‚å¸¸å€¼
            series = series.replace(['#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', 
                                   '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NA', 
                                   'NULL', 'NaN', 'nan'], np.nan)
        
        return series
    
    def _validate_numeric_range(self, series, col_name):
        """éªŒè¯æ•°å€¼èŒƒå›´"""
        if series.dtype in ['int64', 'float64']:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç©·å¤§å€¼
            if np.isinf(series).any():
                logger.warning(f"  åˆ— {col_name} åŒ…å«æ— ç©·å¤§å€¼")
                series.replace([np.inf, -np.inf], np.nan, inplace=True)
            
            # æ£€æŸ¥å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
            if len(series.dropna()) > 0:
                mean_val = series.mean()
                std_val = series.std()
                if std_val > 0:
                    outliers = series[(series < mean_val - 3*std_val) | 
                                    (series > mean_val + 3*std_val)]
                    if len(outliers) > 0:
                        logger.warning(f"  åˆ— {col_name} å‘ç° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
    
    def clean_dataframe(self, df):
        """å®Œæ•´çš„æ•°æ®æ¸…æ´—æµç¨‹"""
        logger.info("=" * 50)
        logger.info("å¼€å§‹æ•°æ®æ¸…æ´—æµç¨‹")
        logger.info("=" * 50)
        
        # 1. è¡¨å¤´æ¸…æ´—
        df, header_mapping = self.clean_headers(df)
        
        # 2. æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯
        df, conversion_stats = self.convert_data_types(df)
        
        # 3. ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š
        self._generate_cleaning_report(df, header_mapping, conversion_stats)
        
        logger.info("=" * 50)
        logger.info("æ•°æ®æ¸…æ´—æµç¨‹å®Œæˆ")
        logger.info("=" * 50)
        
        return df
    
    def _generate_cleaning_report(self, df, header_mapping, conversion_stats):
        """ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š"""
        logger.info("\nğŸ“Š æ•°æ®æ¸…æ´—æŠ¥å‘Š:")
        logger.info(f"  åŸå§‹åˆ—æ•°: {len(df.columns)}")
        logger.info(f"  æ¸…æ´—ååˆ—æ•°: {len(df.columns)}")
        logger.info(f"  è¡¨å¤´æ ‡å‡†åŒ–: {len(header_mapping)} ä¸ªåˆ—åè¢«ä¿®æ”¹")
        logger.info(f"  æ•°å€¼åˆ—è½¬æ¢: {conversion_stats['numeric_converted']} ä¸ª")
        logger.info(f"  ç©ºå€¼å¤„ç†: {conversion_stats['null_values_filled']} ä¸ª")
        
        # ç»Ÿè®¡è€ƒè¯•åˆ—åæ ‡å‡†åŒ–æƒ…å†µ
        exam_columns = [col for col in df.columns if any(exam in col for exam in self.exam_column_patterns['exam_names'])]
        logger.info(f"  è€ƒè¯•åˆ—å: {len(exam_columns)} ä¸ª")
        
        # æ˜¾ç¤ºå‰å‡ åˆ—ä½œä¸ºç¤ºä¾‹
        logger.info(f"\nå‰10åˆ—åç¤ºä¾‹:")
        for i, col in enumerate(df.columns[:10]):
            logger.info(f"  {i+1:2d}: {col}")
        
        if len(df.columns) > 10:
            logger.info(f"  ... è¿˜æœ‰ {len(df.columns) - 10} åˆ—")
        
        # æ˜¾ç¤ºè€ƒè¯•åˆ—åç¤ºä¾‹
        if exam_columns:
            logger.info(f"\nè€ƒè¯•åˆ—åç¤ºä¾‹:")
            for i, col in enumerate(exam_columns[:5]):
                logger.info(f"  {i+1:2d}: {col}")
            if len(exam_columns) > 5:
                logger.info(f"  ... è¿˜æœ‰ {len(exam_columns) - 5} ä¸ªè€ƒè¯•åˆ—å")

def clean_excel_data(file_path, sheet_name=None):
    """ä¾¿æ·å‡½æ•°ï¼šæ¸…æ´—Excelæ•°æ®"""
    try:
        # è¯»å–Excelæ–‡ä»¶
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            logger.info(f"æˆåŠŸè¯»å–å·¥ä½œè¡¨: {sheet_name}")
        else:
            df = pd.read_excel(file_path)
            logger.info(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶")
        
        logger.info(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # åˆ›å»ºæ¸…æ´—å™¨å¹¶æ‰§è¡Œæ¸…æ´—
        cleaner = DataCleaner()
        cleaned_df = cleaner.clean_dataframe(df)
        
        return cleaned_df
        
    except Exception as e:
        logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("æ•°æ®æ¸…æ´—æ¨¡å—æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = {
        'å­¦æ ¡   ä»£ç ': ['001', '002', '003'],
        'å­¦æ ¡åç§°': ['å­¦æ ¡A', 'å­¦æ ¡B', 'å­¦æ ¡C'],
        'ç­   åˆ«': ['1ç­', '2ç­', '3ç­'],
        'è¯­æ–‡ç§‘ä»»': ['å¼ è€å¸ˆ', 'æè€å¸ˆ', 'ç‹è€å¸ˆ'],
        'ä¸­è€ƒ   è¯­æ–‡   å¹³å‡åˆ†   p1': ['85.5', '92.3', '78.9'],
        'ä¸­è€ƒ   è¯­æ–‡   ä¼˜ç§€ç‡   p1': ['25%', '35%', '20%'],
        'ä¸­è€ƒ   è¯­æ–‡   ä¼˜è‰¯ç‡   p1': ['60%', '70%', '55%'],
        'ä¸­è€ƒ   è¯­æ–‡   åˆæ ¼ç‡   p1': ['95%', '98%', '92%'],
        'ä¸­è€ƒ   è¯­æ–‡   ä½åˆ†ç‡   p1': ['5%', '2%', '8%']
    }
    
    test_df = pd.DataFrame(test_data)
    print("åŸå§‹æ•°æ®:")
    print(test_df.head())
    print("\nåˆ—å:", test_df.columns.tolist())
    
    # æ‰§è¡Œæ¸…æ´—
    cleaner = DataCleaner()
    cleaned_df = cleaner.clean_dataframe(test_df)
    
    print("\næ¸…æ´—åæ•°æ®:")
    print(cleaned_df.head())
    print("\næ¸…æ´—ååˆ—å:", cleaned_df.columns.tolist())
